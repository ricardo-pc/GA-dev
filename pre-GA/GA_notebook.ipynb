{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c69c66",
   "metadata": {},
   "source": [
    "## 0. Load and prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d38da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import log\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a659e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>average</th>\n",
       "      <th>obp</th>\n",
       "      <th>runs</th>\n",
       "      <th>hits</th>\n",
       "      <th>doubles</th>\n",
       "      <th>triples</th>\n",
       "      <th>homeruns</th>\n",
       "      <th>rbis</th>\n",
       "      <th>walks</th>\n",
       "      <th>...</th>\n",
       "      <th>rbisperso</th>\n",
       "      <th>walksperso</th>\n",
       "      <th>obppererror</th>\n",
       "      <th>runspererror</th>\n",
       "      <th>hitspererror</th>\n",
       "      <th>hrspererror</th>\n",
       "      <th>soserrors</th>\n",
       "      <th>sbsobp</th>\n",
       "      <th>sbsruns</th>\n",
       "      <th>sbshits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3300</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.302</td>\n",
       "      <td>69</td>\n",
       "      <td>153</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>104</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>17.2500</td>\n",
       "      <td>38.2500</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>320</td>\n",
       "      <td>1.208</td>\n",
       "      <td>276</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.335</td>\n",
       "      <td>58</td>\n",
       "      <td>111</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>27.7500</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>276</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.337</td>\n",
       "      <td>54</td>\n",
       "      <td>115</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>73</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6293</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>19.1667</td>\n",
       "      <td>2.8333</td>\n",
       "      <td>696</td>\n",
       "      <td>2.022</td>\n",
       "      <td>324</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2475</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.292</td>\n",
       "      <td>59</td>\n",
       "      <td>128</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7812</td>\n",
       "      <td>0.3594</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>2.6818</td>\n",
       "      <td>5.8182</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>1408</td>\n",
       "      <td>6.132</td>\n",
       "      <td>1239</td>\n",
       "      <td>2688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2313</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.346</td>\n",
       "      <td>87</td>\n",
       "      <td>169</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0943</td>\n",
       "      <td>1.3208</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>9.6667</td>\n",
       "      <td>18.7778</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>477</td>\n",
       "      <td>1.038</td>\n",
       "      <td>261</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   salary  average    obp  runs  hits  doubles  triples  homeruns  rbis  \\\n",
       "0    3300    0.272  0.302    69   153       21        4        31   104   \n",
       "1    2600    0.269  0.335    58   111       17        2        18    66   \n",
       "2    2500    0.249  0.337    54   115       15        1        17    73   \n",
       "3    2475    0.260  0.292    59   128       22        7        12    50   \n",
       "4    2313    0.273  0.346    87   169       28        5         8    58   \n",
       "\n",
       "   walks  ...  rbisperso  walksperso  obppererror  runspererror  hitspererror  \\\n",
       "0     22  ...     1.3000      0.2750       0.0755       17.2500       38.2500   \n",
       "1     39  ...     0.9565      0.5652       0.0838       14.5000       27.7500   \n",
       "2     63  ...     0.6293      0.5431       0.0562        9.0000       19.1667   \n",
       "3     23  ...     0.7812      0.3594       0.0133        2.6818        5.8182   \n",
       "4     70  ...     1.0943      1.3208       0.0384        9.6667       18.7778   \n",
       "\n",
       "   hrspererror  soserrors  sbsobp  sbsruns  sbshits  \n",
       "0       7.7500        320   1.208      276      612  \n",
       "1       4.5000        276   0.000        0        0  \n",
       "2       2.8333        696   2.022      324      690  \n",
       "3       0.5455       1408   6.132     1239     2688  \n",
       "4       0.8889        477   1.038      261      507  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('baseball.dat', sep=r\"\\s+\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8fdedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw = df['salary'].values\n",
    "\n",
    "# Transform y using natural log because of skewness\n",
    "y = np.log(y_raw) \n",
    "\n",
    "\n",
    "X = df.loc[:, df.columns != 'salary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab22d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 337, Number of predictors: 27\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0] # number of observations (rows)\n",
    "p = X.shape[1] # number of predictors (columns) (27 in this case)\n",
    "print(f\"Number of observations: {n}, Number of predictors: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a685773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute total sum of squares for y\n",
    "mean_y = np.mean(y)\n",
    "\n",
    "# TSS = sum over i=1..n of (y[i] - mean_y)^2\n",
    "TSS = np.sum((y - mean_y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251a7070",
   "metadata": {},
   "source": [
    "## 1. Set GA hyperparameters (fixed for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "793c24d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 20 # Population size\n",
    "G = 50 # Number of generations\n",
    "K = 5 # Folds in cross validation\n",
    "mutation_rate = 0.01 # Mutation rate\n",
    "seed = 42 # Random seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6672d9fa",
   "metadata": {},
   "source": [
    "## 2. Initialize Population (Generation 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a574448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population shape: (20, 27)\n",
      "First chomosome: [1 0 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Population = array/list of length P, each element is a binary vector of length p indicating selected predictors\n",
    "# fitness = array of length P, to store fitness (1 - CV R²) for each individual in the population\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Initialize population: P chromosomes, each of length P (20)\n",
    "# Values are 0 or 1 with equal probability\n",
    "# population is a matrix of shape (P, p), where P = population size (20) and p = number of predictors (27)\n",
    "# each row of population is one chromosome\n",
    "population = (np.random.rand(P, p) < 0.5).astype(int)\n",
    "\n",
    "print(\"Population shape:\", population.shape)\n",
    "print(\"First chomosome:\", population[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2299e98",
   "metadata": {},
   "source": [
    "## 3. Evaluate Fitness for Generation 0 \n",
    "\n",
    "Fitness = K-fold CV R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aabeaf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 fitness values:\n",
      "[0.49385646 0.77251873 0.60717637 0.46302315 0.46510764 0.50044643\n",
      " 0.46657592 0.74180172 0.44833037 0.45795769 0.69440392 0.7601852\n",
      " 0.44502875 0.46852341 0.45466271 0.60983828 0.4582458  0.45970474\n",
      " 0.43428372 0.7538645 ]\n",
      "Best fitness in Gen 0: 0.7725187289767443\n",
      "Index of best individual: 1\n",
      "Best chromosome in Gen 0: [0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# fitness number for each chromosome = how good that model is at predicting unseen salaries\n",
    "# for each chromosome, do K-fold Cross Validation\n",
    "    # split the data into K folds (e.g. 5) of row indices\n",
    "    # for each fold:\n",
    "        # train on K-1 folds\n",
    "        # predict on the left-out fold\n",
    "        # compute squared prediction errors\n",
    "    # Add all squared prediction errors across all folds to get SSPE\n",
    "    # We already have TSS computed\n",
    "    # Compute: R²_cv = 1 - (SSPE / TSS)\n",
    "    # that R²_cv is the fitness for that chromosome\n",
    "# We do for all 20 chromosomes in the population -> we get fitness array of length 20\n",
    "\n",
    "\n",
    "# Create KFold splitter ONCE (we'll reuse its pattern for all chromosomes)\n",
    "# k-fold is a utility from sklearn that generates train/test indices for cross-validation\n",
    "# n-splits=K means we want K folds\n",
    "# shuffle=True means we shuffle the data before splitting into folds\n",
    "# random_state=seed ensures reproducibility\n",
    "# Important: Kfold only cares about the number of rows, not columns, so using X_sel or X is the same here\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "\n",
    "# Initialize fitness array\n",
    "fitness = np.zeros(P)\n",
    "\n",
    "for i in range(P):\n",
    "    # Chromosome i: a 0/1 vector of length p\n",
    "    # population[i, :] is the i-th row, a 1-D array of length p\n",
    "    # b is the chromosome indicating which predictors are selected\n",
    "    b = population[i, :] # shape (p,)\n",
    "\n",
    "    # If chromosome selects no predictors, give terrible fitness\n",
    "    # b.sum() adds up all the 0/1 entries\n",
    "    # If sum is 0, it means no predictors were selected, a model with no predictors is useless and we give it a very bad fitness, so GA will kill it off\n",
    "    # continue jumps to the next i without running CV\n",
    "    if b.sum() == 0:\n",
    "        fitness[i] = -1e9\n",
    "        continue\n",
    "\n",
    "    # Select the columns of X where b[j] == 1\n",
    "    # b == 1 returns a boolean mask of length p\n",
    "    # X[:, b == 1]\n",
    "        # : for rows -> all rows\n",
    "        # b == 1 for columns -> only columns where b[j] is True (1)\n",
    "    # if b has 10 ones, X_sel is n * 10\n",
    "    # this is how we turn the binary chromo`some into a design matrix for regression\n",
    "    X_sel = X[:, b == 1] # matrix with shape (n, num_selected_predictors)\n",
    "\n",
    "    SSPE = 0.0 # Sum of squared prediction errors across all folds\n",
    "\n",
    "    # Cross validation loop\n",
    "    # Loops over k folds\n",
    "    # train_index and test_index are row indices, they work regardless of how many columns X_sel has\n",
    "    # kf.split(X_sel) returns a generator of (train_index, test_index) pairs \n",
    "    # for each fold: \n",
    "        # train_index: indices of rows for training\n",
    "        # test_index: indices of rows for testing\n",
    "    for train_index, test_index in kf.split(X_sel):\n",
    "        X_train = X_sel[train_index, :]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X_sel[test_index, :]\n",
    "        y_test = y[test_index]\n",
    "        # X_train: subset of rows of X_sel for training\n",
    "        # y_train: corresponding subset of y for training\n",
    "        # X_test, y_test: the same for testing\n",
    "\n",
    "        # Fit simple linear regression on training data\n",
    "        # .fit(X_train, y_train) estimates the regression coefficients\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on test data\n",
    "        # y_pred: predicted log-salaries for test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Accumulate squared prediction error\n",
    "        # errors: difference between actual and predicted log-salaries\n",
    "        # np.sum(errors ** 2): sum of squared prediction errors for this fold\n",
    "        errors = y_test - y_pred\n",
    "        SSPE += np.sum(errors ** 2) # Acumulates squared projection errors across all folds\n",
    "\n",
    "    # Compute R² for this chromosome\n",
    "    # SSPE / TSS = proportion of variance in y not explained by the model\n",
    "    # 1 - (SSPE / TSS) = proportion of variance in y explained by predictions on unseen data\n",
    "    R2_cv = 1 - (SSPE / TSS)\n",
    "    fitness[i] = R2_cv\n",
    "\n",
    "\n",
    "# After this loop, 'fitness' holds the Generation 0 fitness for all P individuals\n",
    "print(\"Generation 0 fitness values:\")\n",
    "print(fitness)\n",
    "print(\"Best fitness in Gen 0:\", fitness.max())\n",
    "print(\"Index of best individual:\", fitness.argmax())\n",
    "print(\"Best chromosome in Gen 0:\", population[fitness.argmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87d4e20",
   "metadata": {},
   "source": [
    "## 4. Main GA loop over generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edffd591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial best fitness (Gen 0): 0.7725187289767443\n"
     ]
    }
   ],
   "source": [
    "# Track global best after Generation 0\n",
    "# fitness.max() = best CV-R² found so far\n",
    "# fitness.argmax() = index of best chromosome in population\n",
    "# population[best_index_overall].copy() = best chromosome itself\n",
    "# .copy() to avoid referencing the original array which may change in future generations. Note this for memory management.\n",
    "# best_history will store the best fitness found in each generation (for plotting later)\n",
    "\n",
    "best_fitness_overall = fitness.max()\n",
    "best_index_overall = fitness.argmax()\n",
    "best_chromosome_overall = population[best_index_overall].copy()\n",
    "\n",
    "# Keep history of best fitness per generation (including gen 0)\n",
    "best_history = [best_fitness_overall]\n",
    "\n",
    "print(\"Initial best fitness (Gen 0):\", best_fitness_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9161cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generation 1 ===\n",
      "Best fitness this generation: 0.7731465838380933\n",
      "Best overall fitness so far: 0.7731465838380933\n",
      "\n",
      "=== Generation 2 ===\n",
      "Best fitness this generation: 0.7726258461212423\n",
      "Best overall fitness so far: 0.7731465838380933\n",
      "\n",
      "=== Generation 3 ===\n",
      "Best fitness this generation: 0.7742776748869492\n",
      "Best overall fitness so far: 0.7742776748869492\n",
      "\n",
      "=== Generation 4 ===\n",
      "Best fitness this generation: 0.7676743661243033\n",
      "Best overall fitness so far: 0.7742776748869492\n",
      "\n",
      "=== Generation 5 ===\n",
      "Best fitness this generation: 0.7732234613936992\n",
      "Best overall fitness so far: 0.7742776748869492\n",
      "\n",
      "=== Generation 6 ===\n",
      "Best fitness this generation: 0.7749552645138225\n",
      "Best overall fitness so far: 0.7749552645138225\n",
      "\n",
      "=== Generation 7 ===\n",
      "Best fitness this generation: 0.7759533146983529\n",
      "Best overall fitness so far: 0.7759533146983529\n",
      "\n",
      "=== Generation 8 ===\n",
      "Best fitness this generation: 0.7784703820453748\n",
      "Best overall fitness so far: 0.7784703820453748\n",
      "\n",
      "=== Generation 9 ===\n",
      "Best fitness this generation: 0.7728558486997665\n",
      "Best overall fitness so far: 0.7784703820453748\n",
      "\n",
      "=== Generation 10 ===\n",
      "Best fitness this generation: 0.7805123404875342\n",
      "Best overall fitness so far: 0.7805123404875342\n",
      "\n",
      "=== Generation 11 ===\n",
      "Best fitness this generation: 0.7813597637627856\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 12 ===\n",
      "Best fitness this generation: 0.7805353017305059\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 13 ===\n",
      "Best fitness this generation: 0.7805353017305059\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 14 ===\n",
      "Best fitness this generation: 0.7803084089727995\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 15 ===\n",
      "Best fitness this generation: 0.7805353017305059\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 16 ===\n",
      "Best fitness this generation: 0.7802412766631853\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 17 ===\n",
      "Best fitness this generation: 0.7805353017305059\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 18 ===\n",
      "Best fitness this generation: 0.7806139984807452\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 19 ===\n",
      "Best fitness this generation: 0.7797704529582358\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 20 ===\n",
      "Best fitness this generation: 0.7777866179542174\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 21 ===\n",
      "Best fitness this generation: 0.7794463732087805\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 22 ===\n",
      "Best fitness this generation: 0.7797763141968271\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 23 ===\n",
      "Best fitness this generation: 0.7792589473498678\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 24 ===\n",
      "Best fitness this generation: 0.7792589473498678\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 25 ===\n",
      "Best fitness this generation: 0.7792589473498678\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 26 ===\n",
      "Best fitness this generation: 0.7802543568691168\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 27 ===\n",
      "Best fitness this generation: 0.779993624381438\n",
      "Best overall fitness so far: 0.7813597637627856\n",
      "\n",
      "=== Generation 28 ===\n",
      "Best fitness this generation: 0.7815960451446745\n",
      "Best overall fitness so far: 0.7815960451446745\n",
      "\n",
      "=== Generation 29 ===\n",
      "Best fitness this generation: 0.7814185826953567\n",
      "Best overall fitness so far: 0.7815960451446745\n",
      "\n",
      "=== Generation 30 ===\n",
      "Best fitness this generation: 0.7815960451446745\n",
      "Best overall fitness so far: 0.7815960451446745\n",
      "\n",
      "=== Generation 31 ===\n",
      "Best fitness this generation: 0.7819081985242033\n",
      "Best overall fitness so far: 0.7819081985242033\n",
      "\n",
      "=== Generation 32 ===\n",
      "Best fitness this generation: 0.7814604501670347\n",
      "Best overall fitness so far: 0.7819081985242033\n",
      "\n",
      "=== Generation 33 ===\n",
      "Best fitness this generation: 0.7814604501670347\n",
      "Best overall fitness so far: 0.7819081985242033\n",
      "\n",
      "=== Generation 34 ===\n",
      "Best fitness this generation: 0.7815960451446745\n",
      "Best overall fitness so far: 0.7819081985242033\n",
      "\n",
      "=== Generation 35 ===\n",
      "Best fitness this generation: 0.7824486178421958\n",
      "Best overall fitness so far: 0.7824486178421958\n",
      "\n",
      "=== Generation 36 ===\n",
      "Best fitness this generation: 0.7815960451446745\n",
      "Best overall fitness so far: 0.7824486178421958\n",
      "\n",
      "=== Generation 37 ===\n",
      "Best fitness this generation: 0.7814604501670347\n",
      "Best overall fitness so far: 0.7824486178421958\n",
      "\n",
      "=== Generation 38 ===\n",
      "Best fitness this generation: 0.7810373684885077\n",
      "Best overall fitness so far: 0.7824486178421958\n",
      "\n",
      "=== Generation 39 ===\n",
      "Best fitness this generation: 0.7828445361036646\n",
      "Best overall fitness so far: 0.7828445361036646\n",
      "\n",
      "=== Generation 40 ===\n",
      "Best fitness this generation: 0.7815070296282783\n",
      "Best overall fitness so far: 0.7828445361036646\n",
      "\n",
      "=== Generation 41 ===\n",
      "Best fitness this generation: 0.7815070296282783\n",
      "Best overall fitness so far: 0.7828445361036646\n",
      "\n",
      "=== Generation 42 ===\n",
      "Best fitness this generation: 0.7815070296282783\n",
      "Best overall fitness so far: 0.7828445361036646\n",
      "\n",
      "=== Generation 43 ===\n",
      "Best fitness this generation: 0.7822104057064261\n",
      "Best overall fitness so far: 0.7828445361036646\n",
      "\n",
      "=== Generation 44 ===\n",
      "Best fitness this generation: 0.7822104057064261\n",
      "Best overall fitness so far: 0.7828445361036646\n",
      "\n",
      "=== Generation 45 ===\n",
      "Best fitness this generation: 0.7822104057064261\n",
      "Best overall fitness so far: 0.7828445361036646\n",
      "\n",
      "=== Generation 46 ===\n",
      "Best fitness this generation: 0.7822104057064261\n",
      "Best overall fitness so far: 0.7828445361036646\n",
      "\n",
      "=== Generation 47 ===\n",
      "Best fitness this generation: 0.7822104057064261\n",
      "Best overall fitness so far: 0.7828445361036646\n",
      "\n",
      "=== Generation 48 ===\n",
      "Best fitness this generation: 0.7822104057064261\n",
      "Best overall fitness so far: 0.7828445361036646\n",
      "\n",
      "=== Generation 49 ===\n",
      "Best fitness this generation: 0.7822104057064261\n",
      "Best overall fitness so far: 0.7828445361036646\n",
      "\n",
      "=== Generation 50 ===\n",
      "Best fitness this generation: 0.7822104057064261\n",
      "Best overall fitness so far: 0.7828445361036646\n",
      "\n",
      "=== FINAL RESULT ===\n",
      "Best overall fitness (CV-R^2): 0.7828445361036646\n",
      "Best chromosome (selected predictors):\n",
      "[1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0]\n",
      "Number of predictors selected: 15\n"
     ]
    }
   ],
   "source": [
    "for gen in range(G):\n",
    "    print(f\"\\n=== Generation {gen+1} ===\")\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 4.1 Compute rank-based selection probabilities\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # fitness: array of length P\n",
    "    # We want ranks: 1 (worst) ... P (best)\n",
    "    idx_sorted = np.argsort(fitness)  # gives indices sorted by fitness (smallest -> largest)\n",
    "    ranks = np.zeros(P, dtype=int)\n",
    "\n",
    "    # Assign ranks according to sorted order\n",
    "    # idx_sorted[0] -> rank 1 (worst)\n",
    "    # idx_sorted[-1] -> rank P (best)\n",
    "    for r, idx_individual in enumerate(idx_sorted, start=1):\n",
    "        ranks[idx_individual] = r\n",
    "\n",
    "    # Convert ranks to probabilities\n",
    "    total_rank = ranks.sum()\n",
    "\n",
    "    # probability of choosing each individual for parent 1\n",
    "    # higher fitness -> higher rank -> higher selection probability\n",
    "    selection_prob = ranks / total_rank  # numpy does elementwise division\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 4.2 Create new population using selection, crossover, mutation\n",
    "    # ----------------------------------------\n",
    "\n",
    "   # new_population will store the children of the new generation\n",
    "    new_population = np.zeros_like(population)  # same shape (P, p)\n",
    "    child_count = 0 # counts how many children we've already placed\n",
    "\n",
    "    while child_count < P:\n",
    "\n",
    "        # Parent 1: chosen by selection_prob\n",
    "        # parent1_index is sampled using the probabilities in selection_prob, better individuals more likely to be chosen\n",
    "        parent1_index = np.random.choice(np.arange(P), p=selection_prob)\n",
    "        parent1 = population[parent1_index]\n",
    "\n",
    "        # Parent 2: chosen uniformly at random\n",
    "        # parent2_index is sampled uniformly from 0 to P-1\n",
    "        parent2_index = np.random.randint(P)\n",
    "        parent2 = population[parent2_index]\n",
    "\n",
    "        # Single-point crossover\n",
    "        # Choose crossover point in [1, p-1]\n",
    "        crossover_point = np.random.randint(1, p)\n",
    "\n",
    "        # Create children as copies of parents\n",
    "        child1 = parent1.copy()\n",
    "        child2 = parent2.copy()\n",
    "\n",
    "        # Swap tails after crossover_point\n",
    "        # child1 takes left side from parent1, right side from parent2\n",
    "        # child2 takes left side from parent2, right side from parent1\n",
    "        child1[crossover_point:] = parent2[crossover_point:]\n",
    "        child2[crossover_point:] = parent1[crossover_point:]\n",
    "\n",
    "        # Mutation on child1\n",
    "        # for each position j, we flip the bit with probability mutation_rate. same for child2\n",
    "        for j in range(p):\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                child1[j] = 1 - child1[j]  # flip bit\n",
    "\n",
    "        # Mutation on child2\n",
    "        for j in range(p):\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                child2[j] = 1 - child2[j]\n",
    "\n",
    "        # Add children to new_population\n",
    "        # if P is even, we always add 2 children per iteration\n",
    "        # if P is odd, we just stop when child_count = P\n",
    "        new_population[child_count, :] = child1\n",
    "        child_count += 1\n",
    "\n",
    "        if child_count < P:\n",
    "            new_population[child_count, :] = child2\n",
    "            child_count += 1\n",
    "\n",
    "    # Replace old population\n",
    "    population = new_population\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 4.3 Evaluate fitness of new population (same as Gen 0)\n",
    "    # ----------------------------------------\n",
    "\n",
    "    fitness = np.zeros(P)\n",
    "\n",
    "    for i in range(P):\n",
    "        b = population[i, :]\n",
    "\n",
    "        if b.sum() == 0:\n",
    "            fitness[i] = -1e9\n",
    "            continue\n",
    "\n",
    "        X_sel = X[:, b == 1]\n",
    "\n",
    "        SSPE = 0.0\n",
    "\n",
    "        for train_idx, test_idx in kf.split(X_sel):\n",
    "            X_train = X_sel[train_idx, :]\n",
    "            y_train = y[train_idx]\n",
    "            X_test  = X_sel[test_idx, :]\n",
    "            y_test  = y[test_idx]\n",
    "\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "            errors = y_test - y_pred\n",
    "            SSPE += np.sum(errors ** 2)\n",
    "\n",
    "        R2_cv = 1.0 - (SSPE / TSS)\n",
    "        fitness[i] = R2_cv\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 4.4 Update global best and history\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # best_fitness_gen = best model in this generation\n",
    "    # if it beats overall best, update overall best\n",
    "    best_fitness_gen = fitness.max()\n",
    "    best_index_gen = fitness.argmax()\n",
    "\n",
    "    if best_fitness_gen > best_fitness_overall:\n",
    "        best_fitness_overall = best_fitness_gen\n",
    "        best_chromosome_overall = population[best_index_gen].copy()\n",
    "\n",
    "    best_history.append(best_fitness_overall)\n",
    "\n",
    "    print(\"Best fitness this generation:\", best_fitness_gen)\n",
    "    print(\"Best overall fitness so far:\", best_fitness_overall)\n",
    "\n",
    "# ============================================\n",
    "# 5. After all generations, print final result\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== FINAL RESULT ===\")\n",
    "print(\"Best overall fitness (CV-R^2):\", best_fitness_overall)\n",
    "print(\"Best chromosome (selected predictors):\")\n",
    "print(best_chromosome_overall)\n",
    "print(\"Number of predictors selected:\",\n",
    "      best_chromosome_overall.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
